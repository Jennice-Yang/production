{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing?\n",
    "\n",
    "## Objectives \n",
    "\n",
    "\n",
    "* Build a data pipeline that downloads price data from the internet, stores it locally, transforms it into return data, and stores the feature set.\n",
    "    - Getting the data.\n",
    "    - Schemas and index in dask.\n",
    "\n",
    "* Explore the parquet format.\n",
    "    - Reading and writing parquet files.\n",
    "    - Read datasets that are stored in distributed files.\n",
    "    - Discuss dask vs pandas as a small example of big vs small data.\n",
    "    \n",
    "* Discuss the use of environment variables for settings.\n",
    "* Discuss how to use Jupyter notebooks and source code concurrently. \n",
    "* Logging and using a standard logger.\n",
    "\n",
    "## About the Data\n",
    "\n",
    "+ We will download the prices for a list of stocks.\n",
    "+ The source is Yahoo Finance and we will use the API provided by the library yfinance.\n",
    "\n",
    "\n",
    "## Medallion Architecture\n",
    "\n",
    "+ The architecture that we are thinking about is called Medallion by [DataBricks](https://www.databricks.com/glossary/medallion-architecture). It is an ELT type of thinking, although our data is well-structured.\n",
    "\n",
    "![Medallion Architecture (DataBicks)](./images/02_medallion_architecture.png)\n",
    "\n",
    "+ In our case, we would like to optimize the number of times that we download data from the internet. \n",
    "+ Ultimately, we will build a pipeline manager class that will help us control the process of obtaining and transforming our data.\n",
    "\n",
    "![](./images/02_target_pipeline_manager.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data\n",
    "\n",
    "Download the [Stock Market Dataset from Kaggle](https://www.kaggle.com/datasets/jacksoncrow/stock-market-dataset). Note that you may be required to register for a free account.\n",
    "\n",
    "Extract all files into the directory: `./05_src/data/prices_csv/`\n",
    "\n",
    "Your folder structure should include the following paths:\n",
    "\n",
    "+ `05_src/data/prices_csv/etfs`\n",
    "+ `05_src/data/prices_csv/stocks`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "sys.path.append(os.getenv('SRC_DIR'))\n",
    "\n",
    "from utils.logger import get_logger\n",
    "_logs = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice in the code chunk above:\n",
    "\n",
    "+ Libraries are ordered from high-level to low-level libraries from the package manager (pip in this case, but could be conda, poetry, etc.)\n",
    "+ The command `sys.path.append(\"../05_src/)` will add the `../05_src/` directory to the path in the Notebook's kernel. This way, we can use our modules as part of the notebook.\n",
    "+ Local modules are imported at the end. \n",
    "+ The function `get_logger()` is called with `__name__` as recommended by the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to load the historical price data for stocks and ETFs, we could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 21:43:50,335, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\TNC.csv\n",
      "2025-09-30 21:43:50,487, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\CBB.csv\n",
      "2025-09-30 21:43:50,583, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\ALDX.csv\n",
      "2025-09-30 21:43:50,621, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\GLADD.csv\n",
      "2025-09-30 21:43:50,641, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\FIXX.csv\n",
      "2025-09-30 21:43:50,679, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\ETJ.csv\n",
      "2025-09-30 21:43:50,758, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\CMCTP.csv\n",
      "2025-09-30 21:43:50,777, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\BWG.csv\n",
      "2025-09-30 21:43:50,834, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\VIAC.csv\n",
      "2025-09-30 21:43:50,909, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\REI.csv\n",
      "2025-09-30 21:43:50,976, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\BLPH.csv\n",
      "2025-09-30 21:43:51,016, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\SMG.csv\n",
      "2025-09-30 21:43:51,113, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\MOH.csv\n",
      "2025-09-30 21:43:51,175, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\AMH.csv\n",
      "2025-09-30 21:43:51,213, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\AMAL.csv\n",
      "2025-09-30 21:43:51,235, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\BPYPN.csv\n",
      "2025-09-30 21:43:51,260, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\ERH.csv\n",
      "2025-09-30 21:43:51,327, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\FAMI.csv\n",
      "2025-09-30 21:43:51,349, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\PFG.csv\n",
      "2025-09-30 21:43:51,416, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\SPXC.csv\n",
      "2025-09-30 21:43:51,510, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\ALL.csv\n",
      "2025-09-30 21:43:51,568, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\RTTR.csv\n",
      "2025-09-30 21:43:51,607, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\EARN.csv\n",
      "2025-09-30 21:43:51,636, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\ZIXI.csv\n",
      "2025-09-30 21:43:51,703, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\TSN.csv\n",
      "2025-09-30 21:43:51,779, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\WST.csv\n",
      "2025-09-30 21:43:51,867, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\REG.csv\n",
      "2025-09-30 21:43:51,947, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\MNK.csv\n",
      "2025-09-30 21:43:51,986, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\ESGR.csv\n",
      "2025-09-30 21:43:52,075, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\NGD.csv\n",
      "2025-09-30 21:43:52,153, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\SLRX.csv\n",
      "2025-09-30 21:43:52,202, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\GLW.csv\n",
      "2025-09-30 21:43:52,360, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\ACN.csv\n",
      "2025-09-30 21:43:52,436, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\CSSE.csv\n",
      "2025-09-30 21:43:52,460, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\WORK.csv\n",
      "2025-09-30 21:43:52,483, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\MOS.csv\n",
      "2025-09-30 21:43:52,560, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\IPWR.csv\n",
      "2025-09-30 21:43:52,589, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\GLUU.csv\n",
      "2025-09-30 21:43:52,733, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\CRMT.csv\n",
      "2025-09-30 21:43:52,888, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\EOLS.csv\n",
      "2025-09-30 21:43:52,916, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\INSU.csv\n",
      "2025-09-30 21:43:52,935, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\BWEN.csv\n",
      "2025-09-30 21:43:52,999, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\BPMX.csv\n",
      "2025-09-30 21:43:53,037, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\LH.csv\n",
      "2025-09-30 21:43:53,144, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\BRQS.csv\n",
      "2025-09-30 21:43:53,181, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\KALU.csv\n",
      "2025-09-30 21:43:53,241, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\ITCB.csv\n",
      "2025-09-30 21:43:53,297, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\SRE.csv\n",
      "2025-09-30 21:43:53,375, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\GAZ.csv\n",
      "2025-09-30 21:43:53,424, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\AQMS.csv\n",
      "2025-09-30 21:43:53,458, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\NPK.csv\n",
      "2025-09-30 21:43:53,560, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\QRHC.csv\n",
      "2025-09-30 21:43:53,613, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\CGEN.csv\n",
      "2025-09-30 21:43:53,674, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\LEVL.csv\n",
      "2025-09-30 21:43:53,698, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\BGS.csv\n",
      "2025-09-30 21:43:53,746, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\RIV.csv\n",
      "2025-09-30 21:43:53,768, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\GURE.csv\n",
      "2025-09-30 21:43:53,816, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\TEF.csv\n",
      "2025-09-30 21:43:53,925, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\SYNH.csv\n",
      "2025-09-30 21:43:53,991, 4121356139.py, 10, INFO, Reading file: ../../05_src/data/prices_csv/stocks\\KEY.csv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "stock_files = glob(os.path.join(os.getenv('SRC_DIR'), \"data/prices_csv/stocks/*.csv\"))\n",
    "\n",
    "random.seed(42)\n",
    "stock_files = random.sample(stock_files, 60)\n",
    "\n",
    "dt_list = []\n",
    "for s_file in stock_files:\n",
    "    _logs.info(f\"Reading file: {s_file}\")\n",
    "    dt = pd.read_csv(s_file).assign(\n",
    "        source = os.path.basename(s_file),\n",
    "        ticker = os.path.basename(s_file).replace('.csv', ''),\n",
    "        Date = lambda x: pd.to_datetime(x['Date'])\n",
    "    )\n",
    "    dt_list.append(dt)\n",
    "stock_prices = pd.concat(dt_list, axis = 0, ignore_index = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the structure of the `stock_prices` data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 239659 entries, 0 to 239658\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count   Dtype         \n",
      "---  ------     --------------   -----         \n",
      " 0   Date       239659 non-null  datetime64[ns]\n",
      " 1   Open       239656 non-null  float64       \n",
      " 2   High       239656 non-null  float64       \n",
      " 3   Low        239656 non-null  float64       \n",
      " 4   Close      239656 non-null  float64       \n",
      " 5   Adj Close  239656 non-null  float64       \n",
      " 6   Volume     239656 non-null  float64       \n",
      " 7   source     239659 non-null  object        \n",
      " 8   ticker     239659 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(6), object(2)\n",
      "memory usage: 16.5+ MB\n"
     ]
    }
   ],
   "source": [
    "stock_prices.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can subset our ticker data set using standard indexing techniques. A good reference for this type of data manipulation is Panda's [Documentation](https://pandas.pydata.org/docs/user_guide/indexing.html#indexing-and-selecting-data) and [Cookbook](https://pandas.pydata.org/docs/user_guide/cookbook.html#cookbook-selection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the subset data frame, select one column and convert to list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TNC',\n",
       " 'CBB',\n",
       " 'ALDX',\n",
       " 'GLADD',\n",
       " 'FIXX',\n",
       " 'ETJ',\n",
       " 'CMCTP',\n",
       " 'BWG',\n",
       " 'VIAC',\n",
       " 'REI',\n",
       " 'BLPH',\n",
       " 'SMG',\n",
       " 'MOH',\n",
       " 'AMH',\n",
       " 'AMAL',\n",
       " 'BPYPN',\n",
       " 'ERH',\n",
       " 'FAMI',\n",
       " 'PFG',\n",
       " 'SPXC',\n",
       " 'ALL',\n",
       " 'RTTR',\n",
       " 'EARN',\n",
       " 'ZIXI',\n",
       " 'TSN',\n",
       " 'WST',\n",
       " 'REG',\n",
       " 'MNK',\n",
       " 'ESGR',\n",
       " 'NGD',\n",
       " 'SLRX',\n",
       " 'GLW',\n",
       " 'ACN',\n",
       " 'CSSE',\n",
       " 'WORK',\n",
       " 'MOS',\n",
       " 'IPWR',\n",
       " 'GLUU',\n",
       " 'CRMT',\n",
       " 'EOLS',\n",
       " 'INSU',\n",
       " 'BWEN',\n",
       " 'BPMX',\n",
       " 'LH',\n",
       " 'BRQS',\n",
       " 'KALU',\n",
       " 'ITCB',\n",
       " 'SRE',\n",
       " 'GAZ',\n",
       " 'AQMS',\n",
       " 'NPK',\n",
       " 'QRHC',\n",
       " 'CGEN',\n",
       " 'LEVL',\n",
       " 'BGS',\n",
       " 'RIV',\n",
       " 'GURE',\n",
       " 'TEF',\n",
       " 'SYNH',\n",
       " 'KEY']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_tickers = stock_prices['ticker'].unique().tolist()\n",
    "select_tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data in CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We have some data. How do we store it?\n",
    "+ We can compare two options, CSV and Parqruet, by measuring their performance:\n",
    "\n",
    "    - Time to save.\n",
    "    - Space required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dir_size(path='.'):\n",
    "    '''Returns the total size of files contained in path.'''\n",
    "    total = 0\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = os.getenv(\"TEMP_DATA\")\n",
    "csv_dir = os.path.join(temp, \"csv\")\n",
    "shutil.rmtree(csv_dir, ignore_errors=True)\n",
    "stock_csv = os.path.join(csv_dir, \"stock_px.csv\")\n",
    "os.makedirs(csv_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 21:44:06,248, 473192941.py, 5, INFO, Writing data ((239659, 9)) to csv took 11.441807270050049 seconds.\n",
      "2025-09-30 21:44:06,251, 473192941.py, 6, INFO, CSV file size 26.618403999999998 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "stock_prices.to_csv(stock_csv, index = False)\n",
    "end = time.time()\n",
    "\n",
    "_logs.info(f'Writing data ({stock_prices.shape}) to csv took {end - start} seconds.')\n",
    "_logs.info(f'CSV file size { os.path.getsize(stock_csv)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data to Parquet\n",
    "\n",
    "### Dask \n",
    "\n",
    "We can work with with large data sets and parquet files. In fact, recent versions of pandas support pyarrow data types and future versions will require a pyarrow backend. The pyarrow library is an interface between Python and the Appache Arrow project. The [parquet data format](https://parquet.apache.org/) and [Arrow](https://arrow.apache.org/docs/python/parquet.html) are projects of the Apache Foundation.\n",
    "\n",
    "However, Dask is much more than an interface to Arrow: Dask provides parallel and distributed computing on pandas-like dataframes. It is also relatively easy to use, bridging a gap between pandas and Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (2023.3.0)\n",
      "Collecting dask\n",
      "  Downloading dask-2024.8.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (19.0.0)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-21.0.0-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp39-cp39-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (2.3.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.1 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from dask) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from dask) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from dask) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from dask) (25.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from dask) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from dask) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from dask) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from dask) (8.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from fastparquet) (2.0.2)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.11.0-cp39-cp39-win_amd64.whl.metadata (681 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from click>=8.1->dask) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from importlib-metadata>=4.13.0->dask) (3.23.0)\n",
      "Requirement already satisfied: locket in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from partd>=1.4.0->dask) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading dask-2024.8.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 1.0/1.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading pyarrow-21.0.0-cp39-cp39-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/26.2 MB 6.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 2.6/26.2 MB 6.0 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.7/26.2 MB 5.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 5.0/26.2 MB 5.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.0/26.2 MB 5.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.3/26.2 MB 5.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.7/26.2 MB 5.8 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 10.0/26.2 MB 5.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 11.0/26.2 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.6/26.2 MB 5.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 13.6/26.2 MB 5.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 14.9/26.2 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 16.3/26.2 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.6/26.2 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 18.6/26.2 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 19.7/26.2 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 21.0/26.2 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.3/26.2 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.6/26.2 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.9/26.2 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading fastparquet-2024.11.0-cp39-cp39-win_amd64.whl (671 kB)\n",
      "   ---------------------------------------- 0.0/671.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 671.2/671.2 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading pandas-2.3.3-cp39-cp39-win_amd64.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.4 MB 5.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.4 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/11.4 MB 5.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.5/11.4 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.4 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.1/11.4 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.1/11.4 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.4 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading cramjam-2.11.0-cp39-cp39-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.3/1.7 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow, cramjam, pandas, dask, fastparquet\n",
      "\n",
      "  Attempting uninstall: pyarrow\n",
      "\n",
      "    Found existing installation: pyarrow 19.0.0\n",
      "\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "    Uninstalling pyarrow-19.0.0:\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "      Successfully uninstalled pyarrow-19.0.0\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   ---------------------------------------- 0/5 [pyarrow]\n",
      "   -------- ------------------------------- 1/5 [cramjam]\n",
      "  Attempting uninstall: pandas\n",
      "   -------- ------------------------------- 1/5 [cramjam]\n",
      "    Found existing installation: pandas 2.3.1\n",
      "   -------- ------------------------------- 1/5 [cramjam]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "    Uninstalling pandas-2.3.1:\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "      Successfully uninstalled pandas-2.3.1\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "  Attempting uninstall: dask\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "    Found existing installation: dask 2023.3.0\n",
      "   ---------------- ----------------------- 2/5 [pandas]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "    Uninstalling dask-2023.3.0:\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "      Successfully uninstalled dask-2023.3.0\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   ------------------------ --------------- 3/5 [dask]\n",
      "   -------------------------------- ------- 4/5 [fastparquet]\n",
      "   -------------------------------- ------- 4/5 [fastparquet]\n",
      "   -------------------------------- ------- 4/5 [fastparquet]\n",
      "   ---------------------------------------- 5/5 [fastparquet]\n",
      "\n",
      "Successfully installed cramjam-2.11.0 dask-2024.8.0 fastparquet-2024.11.0 pandas-2.3.3 pyarrow-21.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2023.3.0 requires dask==2023.3.0, but you have dask 2024.8.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade dask pyarrow fastparquet pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "parquet_dir = os.path.join(temp, \"parquet\")\n",
    "shutil.rmtree(parquet_dir, ignore_errors=True)\n",
    "os.makedirs(parquet_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _fs: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m px_dd \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mfrom_pandas(stock_prices, npartitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(select_tickers))\n\u001b[0;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mpx_dd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparquet_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      7\u001b[0m _logs\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWriting dd (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock_prices\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) to parquet took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\dask\\dataframe\\core.py:5642\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[0;32m   5639\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See dd.to_parquet docstring for more information\"\"\"\u001b[39;00m\n\u001b[0;32m   5640\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 5642\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_parquet(\u001b[38;5;28mself\u001b[39m, path, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:839\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, write_index, append, overwrite, ignore_divisions, partition_on, storage_options, custom_metadata, write_metadata_file, compute, compute_kwargs, schema, name_function, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39minferred_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparquet doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support non-string column names\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 839\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    842\u001b[0m     path \u001b[38;5;241m=\u001b[39m stringify_path(path)\n",
      "File \u001b[1;32mc:\\Users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\core.py:1232\u001b[0m, in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m   1230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1232\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowDatasetEngine\n\u001b[0;32m   1234\u001b[0m     _ENGINES[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m eng \u001b[38;5;241m=\u001b[39m ArrowDatasetEngine\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m eng\n",
      "File \u001b[1;32mc:\\Users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\dask\\dataframe\\io\\parquet\\arrow.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpa_fs\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpq\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Check PyArrow version for feature support\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jenni\\miniconda3\\envs\\dsi_participant\\lib\\site-packages\\pyarrow\\fs.py:24\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mFileSystem abstraction to interact with various local and remote filesystems.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_path_like, _stringify_path\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     FileSelector,\n\u001b[0;32m     26\u001b[0m     FileType,\n\u001b[0;32m     27\u001b[0m     FileInfo,\n\u001b[0;32m     28\u001b[0m     FileSystem,\n\u001b[0;32m     29\u001b[0m     LocalFileSystem,\n\u001b[0;32m     30\u001b[0m     SubTreeFileSystem,\n\u001b[0;32m     31\u001b[0m     _MockFileSystem,\n\u001b[0;32m     32\u001b[0m     FileSystemHandler,\n\u001b[0;32m     33\u001b[0m     PyFileSystem,\n\u001b[0;32m     34\u001b[0m     _copy_files,\n\u001b[0;32m     35\u001b[0m     _copy_files_selector,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# For backward compatibility.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m FileStats \u001b[38;5;241m=\u001b[39m FileInfo\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _fs: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "px_dd = dd.from_pandas(stock_prices, npartitions = len(select_tickers))\n",
    "\n",
    "start = time.time()\n",
    "px_dd.to_parquet(parquet_dir, engine = \"pyarrow\")\n",
    "end = time.time()\n",
    "\n",
    "_logs.info(f'Writing dd ({stock_prices.shape}) to parquet took {end - start} seconds.')\n",
    "_logs.info(f'Parquet file size { get_dir_size(parquet_dir)*1e-6 } MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parquet files and Dask Dataframes\n",
    "\n",
    "+ Parquet files are immutable: once written, they cannot be modified.\n",
    "+ Dask DataFrames are a useful implementation to manipulate data stored in parquets.\n",
    "+ Parquet and Dask are not the same: parquet is a file format that can be accessed by many applications and programming languages (Python, R, PowerBI, etc.), while Dask is a package in Python to work with large datasets using distributed computation.\n",
    "+ **Dask is not for everything** (see [Dask DataFrames Best Practices](https://docs.dask.org/en/stable/dataframe-best-practices.html)). \n",
    "\n",
    "    - Consider cases suchas small to large joins, where the small dataframe fits in memory, but the large one does not. \n",
    "    - If possible, use pandas: reduce, then use pandas.\n",
    "    - Pandas performance tips apply to Dask.\n",
    "    - Use the index: it is beneficial to have a well-defined index in Dask DataFrames, as it may speed up searching (filtering) the data. A one-dimensional index is allowed.\n",
    "    - Avoid (or minimize) full-data shuffling: indexing is an expensive operations. \n",
    "    - Some joins are more expensive than others. \n",
    "\n",
    "        * Not expensive:\n",
    "\n",
    "            - Join a Dask DataFrame with a pandas DataFrame.\n",
    "            - Join a Dask DataFrame with another Dask DataFrame of a single partition.\n",
    "            - Join Dask DataFrames along their indexes.\n",
    "\n",
    "        * Expensive:\n",
    "\n",
    "            - Join Dask DataFrames along columns that are not their index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we store prices?\n",
    "\n",
    "+ We can store our data as a single blob. This can be difficult to maintain, especially because parquet files are immutable.\n",
    "+ Strategy: organize data files by ticker and date. Update only latest month.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLean up before start\n",
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")\n",
    "import shutil\n",
    "if os.path.exists(PRICE_DATA):\n",
    "    shutil.rmtree(PRICE_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_prices.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in stock_prices['ticker'].unique():\n",
    "    ticker_dt = stock_prices[stock_prices['ticker'] == ticker]\n",
    "    ticker_dt = ticker_dt.assign(Year = ticker_dt.Date.dt.year)\n",
    "    for yr in ticker_dt['Year'].unique():\n",
    "        yr_dd = dd.from_pandas(ticker_dt[ticker_dt['Year'] == yr],2)\n",
    "        yr_path = os.path.join(PRICE_DATA, ticker, f\"{ticker}_{yr}\")\n",
    "        os.makedirs(os.path.dirname(yr_path), exist_ok=True)\n",
    "        yr_dd.to_parquet(yr_path, engine = \"pyarrow\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would we want to store data this way?\n",
    "\n",
    "+ Easier to maintain. We do not update old data, only recent data.\n",
    "+ We can also access all files as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Transform and Save "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "+ Parquet files can be read individually or as a collection.\n",
    "+ `dd.read_parquet()` can take a list (collection) of files as input.\n",
    "+ Use `glob` to get the collection of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "parquet_files = glob(os.path.join(PRICE_DATA, \"**/*.parquet\"), recursive = True)\n",
    "dd_px = dd.read_parquet(parquet_files).set_index(\"ticker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "+ This transformation step will create a *Features* data set. In our case, features will be stock returns (we obtained prices).\n",
    "+ Dask dataframes work like pandas dataframes: in particular, we can perform groupby and apply operations.\n",
    "+ Notice the use of [an anonymous (lambda) function](https://realpython.com/python-lambda/) in the apply statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_shift = dd_px.groupby('ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(Close_lag_1 = x['Close'].shift(1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_rets = dd_shift.assign(\n",
    "    Returns = lambda x: x['Close']/x['Close_lag_1'] - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Exection\n",
    "\n",
    "What does `dd_rets` contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_rets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Dask is a lazy execution framework: commands will not execute until they are required. \n",
    "+ To trigger an execution in dask use `.compute()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_rets.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "\n",
    "+ Apply transformations to calculate daily returns\n",
    "+ Store the enriched data, the silver dataset, in a new directory.\n",
    "+ Should we keep the same namespace? All columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLean up before save\n",
    "FEATURES_DATA = os.getenv(\"FEATURES_DATA\")\n",
    "if os.path.exists(FEATURES_DATA):\n",
    "    shutil.rmtree(FEATURES_DATA)\n",
    "dd_rets.to_parquet(FEATURES_DATA, overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: from Jupyter to Command Line\n",
    "\n",
    "+ We have drafted our code in a Jupyter Notebook. \n",
    "+ Finalized code should be written in Python modules.\n",
    "\n",
    "## Object Oriented vs Functional Programming\n",
    "\n",
    "+ We can use classes to keep parameters and functions together.\n",
    "+ We *could* use Object Oriented Programming, but parallelization of data manipulation and modelling tasks benefit from *Functional Programming*.\n",
    "+ An Idea: \n",
    "\n",
    "    - [Data Oriented Programming](https://blog.klipse.tech/dop/2022/06/22/principles-of-dop.html).\n",
    "    - Use the class to bundle together parameters and functions.\n",
    "    - Use stateless operations and treat all data objects as immutable (we do not modify them, we overwrite them).\n",
    "    - Take advantage of [`@staticmethod`](https://realpython.com/instance-class-and-static-methods-demystified/).\n",
    "\n",
    "The code is in `./05_src/stock_prices/data_manager.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original design was:\n",
    "\n",
    "![](./images/02_target_pipeline_manager.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_prices.data_manager import DataManager\n",
    "dm = DataManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.process_sample_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add features to the data set and save to a *feature store*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.featurize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
